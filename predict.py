from keras.models import Sequential
from keras.layers import Dense, Activation, LSTM, Dropout
from keras.callbacks import ModelCheckpoint
import numpy as np
from music21 import *

with open('common_variables.txt') as f:
    common_variables = f.read().splitlines()

n_vocab = int(common_variables[0].split(": ")[-1])
network_input = []

for items in common_variables[1: ]:
    l = items[:-1].split(',')
    int_list = []
    for ints in l:
        int_list.append(int(ints))
    network_input.append(int_list)

n_patterns = len(network_input)
sequence_length = 100

network_input_reshaped = np.reshape(network_input, (n_patterns, sequence_length, 1))

model = Sequential()
model.add(LSTM(256, input_shape=(network_input_reshaped.shape[1], network_input_reshaped.shape[2]), return_sequences=True))
model.add(Dropout(0.3))
model.add(LSTM(512, return_sequences=True))
model.add(Dropout(0.3))
model.add(LSTM(256))
model.add(Dense(256))
model.add(Dropout(0.3))
model.add(Dense(n_vocab))
model.add(Activation('softmax'))
model.compile(loss='categorical_crossentropy', optimizer='rmsprop')

pitchnames = []
with open('pitchnames.txt') as f:
    pitchnames = f.read().splitlines()


#load the weights
model.load_weights("weights.hdf5")

start = np.random.randint(0, len(network_input)-1)

int_to_note = dict((number, note) for number, note in enumerate(pitchnames)) #store pitchnames somewhere
n_vocab = len(set(pitchnames))

pattern = network_input[start]
prediction_output = []

#predict 500 notes
for note_index in range(500):
    # print ("Pattern at note_index ",note_index, " :", pattern)
    prediction_input = np.reshape(pattern, (1, len(pattern), 1))
    prediction_input = prediction_input / n_vocab

    prediction = model.predict(prediction_input, verbose=0) #whats verbose

    index = np.argmax(prediction) #get the index of note which has highest probability
    result = int_to_note[index]
    prediction_output.append(result)

    pattern.append(index)
    pattern = pattern[1:len(pattern)]

print (prediction_output)

offset = 0
output_notes = []

#create notes and chord objects based on values generated by model
for pattern in prediction_output:
    #pattern is a note
    if ('.' in pattern) or pattern.isdigit():
        notes_to_chord = pattern.split('.')
        notes_list = []
        for notes in notes_to_chord:
            new_note = note.Note(int(notes))
            new_note.storedInstrument = instrument.Piano()
            notes_list.append(new_note)
        new_chord = chord.Chord()
        new_chord.offset = offset
        output_notes.append(new_chord)
    else:
        new_note = note.Note(pattern)
        new_note.offset = offset
        new_note.storedInstrument = instrument.Piano()
        output_notes.append(new_note)

    offset+=0.5

stream_1 = stream.Stream()
for notes in output_notes:
    stream_1.append(notes)

stream_1.show()
stream_1.show('midi')
